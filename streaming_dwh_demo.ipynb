{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import SparkSession\n",
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"STREAMING_DWH\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS demo;\")\n",
    "spark.sql(\"USE SCHEMA demo;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- cogs: double (nullable = true)\n",
      " |-- contains_caffeine: boolean (nullable = true)\n",
      " |-- contains_fruit: boolean (nullable = true)\n",
      " |-- contains_nuts: boolean (nullable = true)\n",
      " |-- contains_veggies: boolean (nullable = true)\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- item: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To allow automatic schemaInference while reading\n",
    "spark.conf.set(\"spark.sql.streaming.schemaInference\", True)\n",
    "\n",
    "# Create the streaming_df to read from input directory\n",
    "streaming_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"json\") \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .load(\"data/product/\")\n",
    "\n",
    "streaming_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, input_file_name\n",
    "\n",
    "def bronze_streaming_ingestion(source, target):\n",
    "    # Generates a source path based on table name, reads all files from that and inserts into bronze schema\n",
    "\n",
    "    query = (\n",
    "        spark.readStream\n",
    "        .format(\"json\")\n",
    "        .option(\"maxFilesPerTrigger\", 1)\n",
    "        .load(source)\n",
    "        .withColumn(\"meta_timestamp\", current_timestamp())\n",
    "        .withColumn(\"meta_filename\", input_file_name())\n",
    "        .writeStream\n",
    "        .outputMode(\"append\")\n",
    "        .format(\"delta\")\n",
    "        .option(\"checkpointLocation\", f\"spark-warehouse/_checkpoints/{target}\")\n",
    "        .toTable(target)\n",
    "    )\n",
    "    return query\n",
    "\n",
    "query1 = bronze_streaming_ingestion(source=\"data/inventory\", target=\"bronze_inventory\")\n",
    "query2 = bronze_streaming_ingestion(source=\"data/product\", target=\"bronze_product\")\n",
    "query3 = bronze_streaming_ingestion(source=\"data/purchase\", target=\"bronze_purchase\")\n",
    "\n",
    "# Use the code \n",
    "# spark.streams.awaitAnyTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+------------------+-----+----------+------+--------------------+--------------------+\n",
      "|            category|cogs|contains_caffeine|contains_fruit|contains_nuts|contains_veggies|          event_time|              item|price|product_id|  size|      meta_timestamp|       meta_filename|\n",
      "+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+------------------+-----+----------+------+--------------------+--------------------+\n",
      "|Supercharged Smoo...| 2.7|            false|          true|        false|           false|2024-02-17 19:27:...|  Triple Berry Oat| 5.99|      SC01|24 oz.|2024-02-18 20:47:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|           false|2024-02-17 19:27:...|Pomegranate Plunge| 5.99|      SF04|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|            true|2024-02-17 19:27:...|Detox Island Green| 5.99|      SF07|24 oz.|2024-02-18 20:47:...|file:///home/pete...|\n",
      "|Supercharged Smoo...| 2.7|            false|         false|        false|           false|2024-02-17 19:27:...|   Peanut Paradise| 5.99|      SC02|24 oz.|2024-02-18 20:47:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|           false|2024-02-17 19:27:...| Caribbean C-Burst| 5.99|      SF05|24 oz.|2024-02-18 20:47:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|           false|2024-02-17 19:27:...|  Acai Berry Boost| 5.99|      SF03|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...| Rockin’ Raspberry| 4.99|      CS08|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|            true|2024-02-17 19:27:...|   Get Up and Goji| 5.99|      SF06|24 oz.|2024-02-18 20:47:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...|Strawberry Limeade| 4.99|      CS09|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|            true|2024-02-17 19:27:...|     Totally Green| 5.99|      SF02|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|Supercharged Smoo...| 2.7|            false|         false|         true|           false|2024-02-17 19:27:...|        Health Nut| 5.99|      SC03|24 oz.|2024-02-18 20:47:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...|    Sunrise Sunset| 4.99|      CS01|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...|     Kiwi Quencher| 4.99|      CS02|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...|       Jetty Punch| 4.99|      CS11|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...|       Mango Magic| 4.99|      CS05|24 oz.|2024-02-18 20:46:...|file:///home/pete...|\n",
      "+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+------------------+-----+----------+------+--------------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM bronze_product\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOWLY CHANGING DIMENSIONS (SCD) - TYPE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import md5, concat_ws, lit, row_number, monotonically_increasing_id\n",
    "from pyspark.sql.types import BooleanType, TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "from util_functions import reorder_columns_in_dataframe\n",
    "\n",
    "def silver_scd2_dim_table(source, target, merge_key, timestamp_key, surrogate_key):\n",
    "\n",
    "    # Get list of all columns that doesn't contain \"meta_\"\n",
    "    df = spark.sql(f\"select * from {source}\")\n",
    "    df = df.withColumn(\"meta_hashdiff\", md5(concat_ws(\"||\", *[c for c in df.columns if \"meta_\" not in c])))\n",
    "    df = df.withColumn(\"meta_is_current\", lit(1).cast(BooleanType()))\n",
    "    df = df.withColumn(\"meta_valid_from\", df[timestamp_key])\n",
    "    df = df.withColumn(\"meta_valid_to\", lit('9999-12-31').cast(TimestampType()))\n",
    "\n",
    "    # Add partition column\n",
    "    window_spec  = Window.partitionBy(merge_key).orderBy(timestamp_key)\n",
    "    df = df.withColumn(\"meta_sequence\", row_number().over(window_spec))\n",
    "    df = df.withColumn(surrogate_key, monotonically_increasing_id())\n",
    "\n",
    "    # Reorder columns in dataframe\n",
    "    df = reorder_columns_in_dataframe(\n",
    "        df=df, \n",
    "        columns_to_front=[surrogate_key, merge_key],\n",
    "        columns_to_delete=[\"meta_filename\"]\n",
    "    )\n",
    "\n",
    "    # Create an empty Delta table with the same schema\n",
    "    tmp_view_name = \"temporaryView\"\n",
    "    df.createOrReplaceTempView(tmp_view_name)\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {target} LIKE {tmp_view_name} USING DELTA\")\n",
    "\n",
    "    # Get list of sequences\n",
    "    lst_sequence = sorted([p.meta_sequence for p in df.select('meta_sequence').distinct().collect()])\n",
    "\n",
    "    # Run SCD2 table \n",
    "    for seq_num in lst_sequence:\n",
    "        merge_query = f\"\"\"\n",
    "            MERGE INTO {target} AS target\n",
    "            USING (\n",
    "                SELECT * FROM {tmp_view_name}\n",
    "                WHERE meta_sequence = {seq_num}\n",
    "            ) AS source ON target.{merge_key} = source.{merge_key}\n",
    "            WHEN MATCHED AND target.meta_is_current = true AND target.meta_hashdiff <> source.meta_hashdiff\n",
    "                THEN UPDATE SET meta_is_current = false, meta_valid_to = source.{timestamp_key}\n",
    "            WHEN NOT MATCHED \n",
    "                THEN INSERT *\n",
    "        \"\"\"\n",
    "\n",
    "        # Perform merge query\n",
    "        spark.sql(merge_query).show()\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO {target}\n",
    "            SELECT * FROM \n",
    "            (\n",
    "                SELECT source.* \n",
    "                FROM {tmp_view_name} source\n",
    "                JOIN {target} target ON target.{merge_key} = source.{merge_key}\n",
    "                WHERE source.meta_sequence = {seq_num}\n",
    "                AND target.meta_hashdiff <> source.meta_hashdiff \n",
    "            )\n",
    "        \"\"\"\n",
    "        \n",
    "        # Perform insert query\n",
    "        spark.sql(insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|               23|               0|               0|               23|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create SCD2 tables\n",
    "spark.sql(\"DROP TABLE IF EXISTS silver_product_scd2\")\n",
    "\n",
    "silver_scd2_dim_table(\n",
    "    source = \"bronze_product\",\n",
    "    target = \"silver_product_scd2\",\n",
    "    merge_key = \"product_id\",\n",
    "    timestamp_key = \"event_time\",\n",
    "    surrogate_column_name = \"product_sid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-----------------+--------------+-------------+----------------+--------------------------+------------------+-----+----------+------+-----------------------+-----------------------------------------------------+--------------------------------+---------------+--------------------------+-------------------+-------------+-----------+\n",
      "|category         |cogs|contains_caffeine|contains_fruit|contains_nuts|contains_veggies|event_time                |item              |price|product_id|size  |meta_timestamp         |meta_filename                                        |meta_hashdiff                   |meta_is_current|meta_valid_from           |meta_valid_to      |meta_sequence|product_sid|\n",
      "+-----------------+----+-----------------+--------------+-------------+----------------+--------------------------+------------------+-----+----------+------+-----------------------+-----------------------------------------------------+--------------------------------+---------------+--------------------------+-------------------+-------------+-----------+\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.159280|Sunrise Sunset    |4.99 |CS01      |24 oz.|2024-02-18 20:46:13.734|file:///home/peter/data/product/1708198058159380.json|0147022bc45f64893ed3b75973da40c6|true           |2024-02-17 19:27:38.159280|9999-12-31 00:00:00|1            |0          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.164591|Kiwi Quencher     |4.99 |CS02      |24 oz.|2024-02-18 20:46:17.593|file:///home/peter/data/product/1708198058164640.json|2323eb554a8a3025659576b6d6abb2c9|true           |2024-02-17 19:27:38.164591|9999-12-31 00:00:00|1            |1          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.169361|Paradise Point    |4.99 |CS03      |24 oz.|2024-02-18 20:46:20.148|file:///home/peter/data/product/1708198058169406.json|4c968a256ac4452652fcd1fe3a3f0ee9|true           |2024-02-17 19:27:38.169361|9999-12-31 00:00:00|1            |2          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.174798|Sunny Day         |4.99 |CS04      |24 oz.|2024-02-18 20:46:23.176|file:///home/peter/data/product/1708198058174863.json|d36b4c98ab98dbfda4504eb4e1bd9a78|true           |2024-02-17 19:27:38.174798|9999-12-31 00:00:00|1            |3          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.181315|Mango Magic       |4.99 |CS05      |24 oz.|2024-02-18 20:46:26.135|file:///home/peter/data/product/1708198058181371.json|a61592521f1ea72a1c0e1d431a03702e|true           |2024-02-17 19:27:38.181315|9999-12-31 00:00:00|1            |4          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.186888|Blimey Limey      |4.99 |CS06      |24 oz.|2024-02-18 20:46:29.026|file:///home/peter/data/product/1708198058186956.json|010dbd90cd8779f9316ed15faea68a9b|true           |2024-02-17 19:27:38.186888|9999-12-31 00:00:00|1            |5          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.191860|Blueberry Bliss   |4.99 |CS07      |24 oz.|2024-02-18 20:46:31.733|file:///home/peter/data/product/1708198058191938.json|54c13da6e14a155b9da9886c4dd6eba6|true           |2024-02-17 19:27:38.191860|9999-12-31 00:00:00|1            |6          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.198617|Rockin’ Raspberry |4.99 |CS08      |24 oz.|2024-02-18 20:46:34.473|file:///home/peter/data/product/1708198058198673.json|368ad02ff185416ee1537f287ed39d5d|true           |2024-02-17 19:27:38.198617|9999-12-31 00:00:00|1            |7          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.204198|Strawberry Limeade|4.99 |CS09      |24 oz.|2024-02-18 20:46:37.514|file:///home/peter/data/product/1708198058204241.json|0b3da81562edbeff3a69a2254c2bbd7d|true           |2024-02-17 19:27:38.204198|9999-12-31 00:00:00|1            |8          |\n",
      "|Classic Smoothies|1.5 |false            |true          |false        |false           |2024-02-17 19:27:38.209159|Peaches ‘n Silk   |4.99 |CS10      |24 oz.|2024-02-18 20:46:40.795|file:///home/peter/data/product/1708198058209222.json|ccfee152839590857e021b35c53e93e6|true           |2024-02-17 19:27:38.209159|9999-12-31 00:00:00|1            |9          |\n",
      "+-----------------+----+-----------------+--------------+-------------+----------------+--------------------------+------------------+-----+----------+------+-----------------------+-----------------------------------------------------+--------------------------------+---------------+--------------------------+-------------------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from silver_product_scd2 order by product_sid\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Silver Fact Streaming Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_functions import generate_dim_table_references, reorder_columns_in_dataframe\n",
    "\n",
    "def silver_fact_table(\n",
    "    source : str, \n",
    "    target : str,\n",
    "    surrogate_key : str,\n",
    "    timestamp_key : str,\n",
    "    dim_table_refs : dict\n",
    "):\n",
    "\n",
    "    # Generate and run SQL query\n",
    "    df = spark.sql(generate_dim_table_references(source, timestamp_key, dim_table_refs))\n",
    "\n",
    "    # Generate surrogate key\n",
    "    df = df.withColumn(surrogate_key, monotonically_increasing_id())\n",
    "\n",
    "    # Reorder columns\n",
    "    df = reorder_columns_in_dataframe(\n",
    "        df=df, \n",
    "        columns_to_front=[surrogate_key] + [row[\"surrogate_key\"] for row in dim_table_refs],\n",
    "        columns_to_delete=[\"meta_filename\"]\n",
    "    )\n",
    "\n",
    "    df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT src.*, silver_product_scd2.product_sid \n",
      "FROM bronze_purchase src\n",
      "LEFT JOIN silver_product_scd2 ON silver_product_scd2.product_id = src.product_id\n",
      "        AND src.transaction_time BETWEEN silver_product_scd2.meta_valid_from AND silver_product_scd2.meta_valid_to\n",
      "+---------------+-----------+---------------+---------+---------------+--------------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+\n",
      "|transaction_sid|product_sid|add_supplements|is_member|member_discount|      meta_timestamp|price|product_id|quantity|supplement_price|total_purchase|     transaction_id|    transaction_time|\n",
      "+---------------+-----------+---------------+---------+---------------+--------------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+\n",
      "|              0|          3|          false|    false|            0.0|2024-02-18 20:47:...| 4.99|      CS04|       2|             0.0|          9.98|8551749179120170063|2024-02-17 19:28:...|\n",
      "|              1|          4|          false|    false|            0.0|2024-02-18 20:46:...| 4.99|      CS05|       1|             0.0|          4.99|2780732063114476572|2024-02-17 19:28:...|\n",
      "|              2|       NULL|          false|    false|            0.0|2024-02-18 20:47:...| 5.49|      IS04|       1|             0.0|          5.49|1247169080166844079|2024-02-17 19:28:...|\n",
      "|     8589934592|       NULL|           true|    false|            0.0|2024-02-18 20:46:...| 5.49|      IS02|       1|            1.99|          7.48|4455419090920518032|2024-02-17 19:28:...|\n",
      "|     8589934593|          6|           true|    false|            0.0|2024-02-18 20:46:...| 4.99|      CS07|       2|            1.99|         13.96|1830085331582317580|2024-02-17 19:27:...|\n",
      "+---------------+-----------+---------------+---------+---------------+--------------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "SELECT src.*, silver_product_scd2.product_sid \n",
      "FROM bronze_inventory src\n",
      "LEFT JOIN silver_product_scd2 ON silver_product_scd2.product_id = src.product_id\n",
      "        AND src.event_time BETWEEN silver_product_scd2.meta_valid_from AND silver_product_scd2.meta_valid_to\n",
      "+-------------+-----------+--------------------+--------------+--------------------+---------+----------+--------------+\n",
      "|inventory_sid|product_sid|          event_time|existing_level|      meta_timestamp|new_level|product_id|stock_quantity|\n",
      "+-------------+-----------+--------------------+--------------+--------------------+---------+----------+--------------+\n",
      "|            0|         21|2024-02-17 19:27:...|            49|2024-02-18 20:46:...|       59|      SF06|            10|\n",
      "|            1|         19|2024-02-17 19:32:...|            49|2024-02-18 20:46:...|       59|      SF04|            10|\n",
      "|            2|         14|2024-02-17 19:33:...|            50|2024-02-18 20:47:...|       60|      SC04|            10|\n",
      "|            3|         15|2024-02-17 19:33:...|            43|2024-02-18 20:47:...|       53|      SC05|            10|\n",
      "|   8589934592|         13|2024-02-17 19:27:...|            34|2024-02-18 20:46:...|       44|      SC03|            10|\n",
      "+-------------+-----------+--------------------+--------------+--------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "silver_fact_table (\n",
    "    source=\"bronze_purchase\",\n",
    "    target=\"silver_purchase\",\n",
    "    surrogate_key=\"transaction_sid\",\n",
    "    timestamp_key=\"transaction_time\",\n",
    "    dim_table_refs=[{\"table_name\": \"silver_product_scd2\", \"merge_key\": \"product_id\", \"surrogate_key\": \"product_sid\"}]\n",
    ")\n",
    "\n",
    "silver_fact_table (\n",
    "    source=\"bronze_inventory\",\n",
    "    target=\"silver_inventory\",\n",
    "    surrogate_key=\"inventory_sid\",\n",
    "    timestamp_key=\"event_time\",\n",
    "    dim_table_refs=[{\"table_name\": \"silver_product_scd2\", \"merge_key\": \"product_id\", \"surrogate_key\": \"product_sid\"}]\n",
    ")\n",
    "\n",
    "# if spark.catalog.tableExists(target):\n",
    "#     df = spark.sql(f\"SELECT * FROM {source} WHERE {source}.{timestamp_key} > (SELECT MAX({timestamp_key}) FROM {target})\")\n",
    "# else:\n",
    "#     df = spark.sql(f\"SELECT * FROM {source}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[event_time: string, existing_level: bigint, new_level: bigint, product_id: string, stock_quantity: bigint, meta_timestamp: timestamp, meta_filename: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from bronze_inventory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
