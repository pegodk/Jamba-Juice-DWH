{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import SparkSession\n",
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"STREAMING_DWH\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- cogs: double (nullable = true)\n",
      " |-- contains_caffeine: boolean (nullable = true)\n",
      " |-- contains_fruit: boolean (nullable = true)\n",
      " |-- contains_nuts: boolean (nullable = true)\n",
      " |-- contains_veggies: boolean (nullable = true)\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- item: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To allow automatic schemaInference while reading\n",
    "spark.conf.set(\"spark.sql.streaming.schemaInference\", True)\n",
    "\n",
    "# Create the streaming_df to read from input directory\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"json\") \\\n",
    "    .load(\"data/product/\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, input_file_name\n",
    "\n",
    "def create_bronze_streaming_table(source, target):\n",
    "    # Generates a source path based on table name, reads all files from that and inserts into bronze schema\n",
    "\n",
    "    query = (\n",
    "        spark.readStream\n",
    "        .format(\"json\")\n",
    "        .load(source)\n",
    "        .withColumn(\"meta_ingestion_ts\", current_timestamp())\n",
    "        .withColumn(\"meta_filename\", input_file_name())\n",
    "        .writeStream\n",
    "        .outputMode(\"append\")\n",
    "        .format(\"delta\")\n",
    "        .option(\"checkpointLocation\", f\"spark-warehouse/_checkpoints/{target}\")\n",
    "        .toTable(target)\n",
    "    )\n",
    "    return query\n",
    "\n",
    "query1 = create_bronze_streaming_table(source=\"data/inventory\", target=\"bronze_inventory\")\n",
    "query2 = create_bronze_streaming_table(source=\"data/product\", target=\"bronze_product\")\n",
    "query3 = create_bronze_streaming_table(source=\"data/purchase\", target=\"bronze_purchase\")\n",
    "\n",
    "# Use the code \n",
    "# spark.streams.awaitAnyTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+------------------+-----+----------+------+--------------------+--------------------+\n",
      "|            category|cogs|contains_caffeine|contains_fruit|contains_nuts|contains_veggies|          event_time|              item|price|product_id|  size|   meta_ingestion_ts|       meta_filename|\n",
      "+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+------------------+-----+----------+------+--------------------+--------------------+\n",
      "| Indulgent Smoothies| 2.2|            false|         false|         true|           false|2024-02-17 19:27:...| Peanut Butter Cup| 5.49|      IS02|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|           false|2024-02-17 19:32:...|  Acai Berry Boost| 5.99|      SF03|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "| Indulgent Smoothies| 2.2|            false|         false|         true|           false|2024-02-17 19:32:...| Peanut Butter Cup| 5.49|      IS02|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|Superfoods Smoothies| 2.1|            false|          true|        false|           false|2024-02-18 19:26:...|  Acai Berry Boost| 5.99|      SF03|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "| Indulgent Smoothies| 2.2|            false|         false|         true|           false|2024-02-18 19:26:...| Peanut Butter Cup| 5.49|      IS02|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:27:...|Strawberry Limeade| 4.99|      CS09|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|Supercharged Smoo...| 2.7|             true|         false|         true|           false|2024-02-17 19:27:...|    Muscle Blaster| 5.99|      SC05|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-17 19:32:...|Strawberry Limeade| 4.99|      CS09|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|Supercharged Smoo...| 2.7|             true|         false|         true|           false|2024-02-17 19:32:...|    Muscle Blaster| 5.99|      SC05|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-18 19:26:...|Strawberry Limeade| 4.99|      CS09|24 oz.|2024-02-20 20:14:...|file:///home/pete...|\n",
      "+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+------------------+-----+----------+------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM bronze_product\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SILVER TABLES: SLOWLY CHANGING DIMENSIONS (SCD) - TYPE 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import md5, concat_ws, lit, row_number, monotonically_increasing_id\n",
    "from pyspark.sql.types import BooleanType, TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "from utils import reorder_columns_in_dataframe\n",
    "\n",
    "def create_silver_scd1_table(\n",
    "    source : str, \n",
    "    target : str,\n",
    "    timestamp_key : str,\n",
    "    surrogate_key : str\n",
    "):\n",
    "\n",
    "    # Load data and calculate hashdiff string based on all columns that doesn't contain \"meta_\" in the name\n",
    "    df = spark.sql(f\"select * from {source} order by {timestamp_key}\")\n",
    "    df = df.withColumn(\"meta_hashdiff\", md5(concat_ws(\"||\", *[c for c in df.columns if \"meta_\" not in c])))\n",
    "\n",
    "    # Set default values for meta_last_updated\n",
    "    df = df.withColumn(\"meta_last_updated\", current_timestamp())\n",
    "\n",
    "    # Generate surrogate key\n",
    "    df = df.withColumn(surrogate_key, monotonically_increasing_id())\n",
    "\n",
    "    # Reorder columns\n",
    "    df = reorder_columns_in_dataframe(df=df, \n",
    "                                      columns_to_front=[surrogate_key],\n",
    "                                      columns_to_back=[c for c in df.columns if \"meta_\" in c],\n",
    "                                      columns_to_delete=[\"meta_filename\"])\n",
    "    \n",
    "    # Create an empty Delta table with the same schema\n",
    "    tmp_view_name = \"temporaryView\"\n",
    "    df.createOrReplaceTempView(tmp_view_name)\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {target} LIKE {tmp_view_name} USING DELTA\")\n",
    "\n",
    "    # Merge into target table \n",
    "    merge_query = f\"\"\"\n",
    "        MERGE INTO {target} AS target\n",
    "        USING {tmp_view_name} AS source ON target.{surrogate_key} = source.{surrogate_key}\n",
    "        WHEN MATCHED AND target.meta_hashdiff <> source.meta_hashdiff THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\"\n",
    "    spark.sql(merge_query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|              139|               0|               0|              139|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|               35|               0|               0|               35|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_silver_scd1_table (\n",
    "    source=\"bronze_purchase\",\n",
    "    target=\"silver_purchase_scd1\",\n",
    "    surrogate_key=\"transaction_sid\",\n",
    ")\n",
    "\n",
    "create_silver_scd1_table (\n",
    "    source=\"bronze_inventory\",\n",
    "    target=\"silver_inventory_scd1\",\n",
    "    surrogate_key=\"inventory_sid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silver_scd2_table(source, target, merge_key, timestamp_key, surrogate_key):\n",
    "\n",
    "    # Load data and calculate hashdiff string based on all columns that doesn't contain \"meta_\" in the name\n",
    "    df = spark.sql(f\"select * from {source}\")\n",
    "    df = df.withColumn(\"meta_hashdiff\", md5(concat_ws(\"||\", *[c for c in df.columns if \"meta_\" not in c])))\n",
    "\n",
    "    # Set default values for meta columns\n",
    "    df = df.withColumn(\"meta_is_current\", lit(1).cast(BooleanType()))\n",
    "    df = df.withColumn(\"meta_valid_from\", df[timestamp_key])\n",
    "    df = df.withColumn(\"meta_valid_to\", lit('9999-12-31').cast(TimestampType()))\n",
    "\n",
    "    # Calculate surrogate key\n",
    "    df = df.withColumn(surrogate_key, monotonically_increasing_id())\n",
    "\n",
    "    # Calculate sequence numbers if source data contain multiple rows for each merge_key\n",
    "    window_spec = Window.partitionBy(merge_key).orderBy(timestamp_key)\n",
    "    df = df.withColumn(\"meta_sequence\", row_number().over(window_spec))\n",
    "\n",
    "    # Reorder columns in dataframe\n",
    "    df = reorder_columns_in_dataframe(\n",
    "        df=df, \n",
    "        columns_to_front=[surrogate_key, merge_key],\n",
    "        columns_to_back=[c for c in df.columns if \"meta_\" in c],\n",
    "        columns_to_delete=[\"meta_filename\"]\n",
    "    )\n",
    "\n",
    "    # Create an empty Delta table with the same schema\n",
    "    tmp_view_name = \"temporaryView\"\n",
    "    df.createOrReplaceTempView(tmp_view_name)\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {target} LIKE {tmp_view_name} USING DELTA\")\n",
    "\n",
    "    # Get list of sequences\n",
    "    lst_sequence = sorted([p.meta_sequence for p in df.select('meta_sequence').distinct().collect()])\n",
    "\n",
    "    # Run SCD2 table \n",
    "    for seq_num in lst_sequence:\n",
    "        merge_query = f\"\"\"\n",
    "            MERGE INTO {target} AS target\n",
    "            USING (\n",
    "                SELECT * FROM {tmp_view_name}\n",
    "                WHERE meta_sequence = {seq_num}\n",
    "            ) AS source ON target.{merge_key} = source.{merge_key}\n",
    "            WHEN MATCHED AND target.meta_is_current = true AND target.meta_hashdiff <> source.meta_hashdiff\n",
    "                THEN UPDATE SET meta_is_current = false, meta_valid_to = source.{timestamp_key}\n",
    "            WHEN NOT MATCHED \n",
    "                THEN INSERT *\n",
    "        \"\"\"\n",
    "        spark.sql(merge_query).show()\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO {target}\n",
    "            SELECT * FROM \n",
    "            (\n",
    "                SELECT source.* \n",
    "                FROM {tmp_view_name} source\n",
    "                JOIN {target} target ON target.{merge_key} = source.{merge_key}\n",
    "                WHERE source.meta_sequence = {seq_num}\n",
    "                AND target.meta_hashdiff <> source.meta_hashdiff \n",
    "            )\n",
    "        \"\"\"\n",
    "        spark.sql(insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|               54|              54|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.CAST_WITH_CONF_SUGGESTION] Cannot resolve \"meta_is_current\" due to data type mismatch: cannot cast \"BOOLEAN\" to \"TIMESTAMP\" with ANSI mode on.\nIf you have to cast \"BOOLEAN\" to \"TIMESTAMP\", you can set \"spark.sql.storeAssignmentPolicy\" as 'LEGACY'.; line 2 pos 12;\n'AppendData RelationV2[product_sid#24236L, product_id#24237, category#24238, cogs#24239, contains_caffeine#24240, contains_fruit#24241, contains_nuts#24242, contains_veggies#24243, event_time#24244, item#24245, meta_hashdiff#24246, meta_ingestion_ts#24247, meta_is_current#24248, meta_sequence#24249, meta_valid_from#24250, meta_valid_to#24251, price#24252, size#24253] spark_catalog.default.silver_product_scd2 spark_catalog.default.silver_product_scd2, false\n+- 'Project [product_sid#22203L AS product_sid#24255L, product_id#22119 AS product_id#24256, category#22110 AS category#24257, cogs#22111 AS cogs#24258, contains_caffeine#22112 AS contains_caffeine#24259, contains_fruit#22113 AS contains_fruit#24260, contains_nuts#22114 AS contains_nuts#24261, contains_veggies#22115 AS contains_veggies#24262, event_time#22116 AS event_time#24263, item#22117 AS item#24264, cast(meta_sequence#22223 as string) AS meta_hashdiff#24265, cast(price#22118 as timestamp) AS meta_ingestion_ts#24266, cast(size#22120 as boolean) AS meta_is_current#24267, cast(meta_hashdiff#22137 as int) AS meta_sequence#24268, cast(meta_ingestion_ts#22121 as string) AS meta_valid_from#24269, cast(meta_is_current#22152 as timestamp) AS meta_valid_to#24270, cast(meta_valid_from#22168 as double) AS price#24271, cast(meta_valid_to#22185 as string) AS size#24272]\n   +- Project [product_sid#22203L, product_id#22119, category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, meta_sequence#22223, price#22118, size#22120, meta_hashdiff#22137, meta_ingestion_ts#22121, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185]\n      +- SubqueryAlias __auto_generated_subquery_name\n         +- Project [product_sid#22203L, product_id#22119, category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, meta_sequence#22223, price#22118, size#22120, meta_hashdiff#22137, meta_ingestion_ts#22121, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185]\n            +- Filter ((meta_sequence#22223 = 1) AND NOT (meta_hashdiff#24228 = meta_hashdiff#22137))\n               +- Join Inner, (product_id#24219 = product_id#22119)\n                  :- SubqueryAlias source\n                  :  +- SubqueryAlias temporaryview\n                  :     +- View (`temporaryView`, [product_sid#22203L,product_id#22119,category#22110,cogs#22111,contains_caffeine#22112,contains_fruit#22113,contains_nuts#22114,contains_veggies#22115,event_time#22116,item#22117,meta_sequence#22223,price#22118,size#22120,meta_hashdiff#22137,meta_ingestion_ts#22121,meta_is_current#22152,meta_valid_from#22168,meta_valid_to#22185])\n                  :        +- Project [product_sid#22203L, product_id#22119, category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, meta_sequence#22223, price#22118, size#22120, meta_hashdiff#22137, meta_ingestion_ts#22121, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185]\n                  :           +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, product_sid#22203L, meta_sequence#22223]\n                  :              +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, product_sid#22203L, meta_sequence#22223, meta_sequence#22223]\n                  :                 +- Window [row_number() windowspecdefinition(product_id#22119, event_time#22116 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS meta_sequence#22223], [product_id#22119], [event_time#22116 ASC NULLS FIRST]\n                  :                    +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, product_sid#22203L]\n                  :                       +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, monotonically_increasing_id() AS product_sid#22203L]\n                  :                          +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, cast(9999-12-31 as timestamp) AS meta_valid_to#22185]\n                  :                             +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, event_time#22116 AS meta_valid_from#22168]\n                  :                                +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, cast(1 as boolean) AS meta_is_current#22152]\n                  :                                   +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, md5(cast(concat_ws(||, category#22110, cast(cogs#22111 as string), cast(contains_caffeine#22112 as string), cast(contains_fruit#22113 as string), cast(contains_nuts#22114 as string), cast(contains_veggies#22115 as string), event_time#22116, item#22117, cast(price#22118 as string), product_id#22119, size#22120) as binary)) AS meta_hashdiff#22137]\n                  :                                      +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122]\n                  :                                         +- SubqueryAlias spark_catalog.default.bronze_product\n                  :                                            +- Relation spark_catalog.default.bronze_product[category#22110,cogs#22111,contains_caffeine#22112,contains_fruit#22113,contains_nuts#22114,contains_veggies#22115,event_time#22116,item#22117,price#22118,product_id#22119,size#22120,meta_ingestion_ts#22121,meta_filename#22122] parquet\n                  +- SubqueryAlias target\n                     +- SubqueryAlias spark_catalog.default.silver_product_scd2\n                        +- Relation spark_catalog.default.silver_product_scd2[product_sid#24218L,product_id#24219,category#24220,cogs#24221,contains_caffeine#24222,contains_fruit#24223,contains_nuts#24224,contains_veggies#24225,event_time#24226,item#24227,meta_hashdiff#24228,meta_ingestion_ts#24229,meta_is_current#24230,meta_sequence#24231,meta_valid_from#24232,meta_valid_to#24233,price#24234,size#24235] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create SCD2 tables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msilver_scd2_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbronze_product\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msilver_product_scd2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmerge_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msurrogate_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct_sid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 61\u001b[0m, in \u001b[0;36msilver_scd2_table\u001b[0;34m(source, target, merge_key, timestamp_key, surrogate_key)\u001b[0m\n\u001b[1;32m     48\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(merge_query)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     50\u001b[0m insert_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124m    INSERT INTO \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m    SELECT * FROM \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.CAST_WITH_CONF_SUGGESTION] Cannot resolve \"meta_is_current\" due to data type mismatch: cannot cast \"BOOLEAN\" to \"TIMESTAMP\" with ANSI mode on.\nIf you have to cast \"BOOLEAN\" to \"TIMESTAMP\", you can set \"spark.sql.storeAssignmentPolicy\" as 'LEGACY'.; line 2 pos 12;\n'AppendData RelationV2[product_sid#24236L, product_id#24237, category#24238, cogs#24239, contains_caffeine#24240, contains_fruit#24241, contains_nuts#24242, contains_veggies#24243, event_time#24244, item#24245, meta_hashdiff#24246, meta_ingestion_ts#24247, meta_is_current#24248, meta_sequence#24249, meta_valid_from#24250, meta_valid_to#24251, price#24252, size#24253] spark_catalog.default.silver_product_scd2 spark_catalog.default.silver_product_scd2, false\n+- 'Project [product_sid#22203L AS product_sid#24255L, product_id#22119 AS product_id#24256, category#22110 AS category#24257, cogs#22111 AS cogs#24258, contains_caffeine#22112 AS contains_caffeine#24259, contains_fruit#22113 AS contains_fruit#24260, contains_nuts#22114 AS contains_nuts#24261, contains_veggies#22115 AS contains_veggies#24262, event_time#22116 AS event_time#24263, item#22117 AS item#24264, cast(meta_sequence#22223 as string) AS meta_hashdiff#24265, cast(price#22118 as timestamp) AS meta_ingestion_ts#24266, cast(size#22120 as boolean) AS meta_is_current#24267, cast(meta_hashdiff#22137 as int) AS meta_sequence#24268, cast(meta_ingestion_ts#22121 as string) AS meta_valid_from#24269, cast(meta_is_current#22152 as timestamp) AS meta_valid_to#24270, cast(meta_valid_from#22168 as double) AS price#24271, cast(meta_valid_to#22185 as string) AS size#24272]\n   +- Project [product_sid#22203L, product_id#22119, category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, meta_sequence#22223, price#22118, size#22120, meta_hashdiff#22137, meta_ingestion_ts#22121, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185]\n      +- SubqueryAlias __auto_generated_subquery_name\n         +- Project [product_sid#22203L, product_id#22119, category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, meta_sequence#22223, price#22118, size#22120, meta_hashdiff#22137, meta_ingestion_ts#22121, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185]\n            +- Filter ((meta_sequence#22223 = 1) AND NOT (meta_hashdiff#24228 = meta_hashdiff#22137))\n               +- Join Inner, (product_id#24219 = product_id#22119)\n                  :- SubqueryAlias source\n                  :  +- SubqueryAlias temporaryview\n                  :     +- View (`temporaryView`, [product_sid#22203L,product_id#22119,category#22110,cogs#22111,contains_caffeine#22112,contains_fruit#22113,contains_nuts#22114,contains_veggies#22115,event_time#22116,item#22117,meta_sequence#22223,price#22118,size#22120,meta_hashdiff#22137,meta_ingestion_ts#22121,meta_is_current#22152,meta_valid_from#22168,meta_valid_to#22185])\n                  :        +- Project [product_sid#22203L, product_id#22119, category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, meta_sequence#22223, price#22118, size#22120, meta_hashdiff#22137, meta_ingestion_ts#22121, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185]\n                  :           +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, product_sid#22203L, meta_sequence#22223]\n                  :              +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, product_sid#22203L, meta_sequence#22223, meta_sequence#22223]\n                  :                 +- Window [row_number() windowspecdefinition(product_id#22119, event_time#22116 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS meta_sequence#22223], [product_id#22119], [event_time#22116 ASC NULLS FIRST]\n                  :                    +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, product_sid#22203L]\n                  :                       +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, meta_valid_to#22185, monotonically_increasing_id() AS product_sid#22203L]\n                  :                          +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, meta_valid_from#22168, cast(9999-12-31 as timestamp) AS meta_valid_to#22185]\n                  :                             +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, meta_is_current#22152, event_time#22116 AS meta_valid_from#22168]\n                  :                                +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, meta_hashdiff#22137, cast(1 as boolean) AS meta_is_current#22152]\n                  :                                   +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122, md5(cast(concat_ws(||, category#22110, cast(cogs#22111 as string), cast(contains_caffeine#22112 as string), cast(contains_fruit#22113 as string), cast(contains_nuts#22114 as string), cast(contains_veggies#22115 as string), event_time#22116, item#22117, cast(price#22118 as string), product_id#22119, size#22120) as binary)) AS meta_hashdiff#22137]\n                  :                                      +- Project [category#22110, cogs#22111, contains_caffeine#22112, contains_fruit#22113, contains_nuts#22114, contains_veggies#22115, event_time#22116, item#22117, price#22118, product_id#22119, size#22120, meta_ingestion_ts#22121, meta_filename#22122]\n                  :                                         +- SubqueryAlias spark_catalog.default.bronze_product\n                  :                                            +- Relation spark_catalog.default.bronze_product[category#22110,cogs#22111,contains_caffeine#22112,contains_fruit#22113,contains_nuts#22114,contains_veggies#22115,event_time#22116,item#22117,price#22118,product_id#22119,size#22120,meta_ingestion_ts#22121,meta_filename#22122] parquet\n                  +- SubqueryAlias target\n                     +- SubqueryAlias spark_catalog.default.silver_product_scd2\n                        +- Relation spark_catalog.default.silver_product_scd2[product_sid#24218L,product_id#24219,category#24220,cogs#24221,contains_caffeine#24222,contains_fruit#24223,contains_nuts#24224,contains_veggies#24225,event_time#24226,item#24227,meta_hashdiff#24228,meta_ingestion_ts#24229,meta_is_current#24230,meta_sequence#24231,meta_valid_from#24232,meta_valid_to#24233,price#24234,size#24235] parquet\n"
     ]
    }
   ],
   "source": [
    "# Create SCD2 tables\n",
    "silver_scd2_table(\n",
    "    source = \"bronze_product\",\n",
    "    target = \"silver_product_scd2\",\n",
    "    merge_key = \"product_id\",\n",
    "    timestamp_key = \"event_time\",\n",
    "    surrogate_key = \"product_sid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+---------+---------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|transaction_sid|add_supplements|is_member|member_discount|price|product_id|quantity|supplement_price|total_purchase|     transaction_id|    transaction_time|       meta_hashdiff|   meta_ingestion_ts|   meta_last_updated|\n",
      "+---------------+---------------+---------+---------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|              0|           true|    false|            0.0| 4.99|      CS07|       2|            1.99|         13.96|1830085331582317580|2024-02-17 19:27:...|61f75a7278ee6b97a...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|              1|           true|    false|            0.0| 5.99|      SF07|       2|            1.99|         15.96|2582918047038672240|2024-02-17 19:28:...|2498c9c86aebcfecf...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|              2|          false|    false|            0.0| 5.99|      SC03|       2|             0.0|         11.98|6679341482214175713|2024-02-17 19:29:...|85cde6aebb6d2deb7...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|              3|           true|    false|            0.0| 4.99|      CS06|       2|            1.99|         13.96|4642186432042039094|2024-02-17 19:32:...|f733a0370ead91420...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|              4|          false|    false|            0.0| 5.49|      IS02|       2|             0.0|         10.98|7153639856726240807|2024-02-17 19:33:...|d98e4aac5b2c40a22...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "+---------------+---------------+---------+---------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+--------------------+--------------+---------+----------+--------------+--------------------+--------------------+--------------------+\n",
      "|inventory_sid|          event_time|existing_level|new_level|product_id|stock_quantity|       meta_hashdiff|   meta_ingestion_ts|   meta_last_updated|\n",
      "+-------------+--------------------+--------------+---------+----------+--------------+--------------------+--------------------+--------------------+\n",
      "|   8589934592|2024-02-18 19:27:...|            34|       44|      SC03|            10|9d3d32fb5b0c6ce1d...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|   8589934593|2024-02-18 19:27:...|            48|       58|      SF01|            10|1062007da4d8e27de...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|   8589934594|2024-02-18 19:27:...|            34|       44|      SC05|            10|f8e58d2ef6e044972...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|   8589934595|2024-02-18 19:27:...|            43|       53|      SC05|            10|4317c6d77d2277eaa...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "|   8589934596|2024-02-18 19:27:...|            47|       57|      SF07|            10|dae9c90247519eaad...|2024-02-20 20:14:...|2024-02-20 20:17:...|\n",
      "+-------------+--------------------+--------------+---------+----------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+----------+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+---------------+--------------------+--------------------+---------------+-------------+--------------------+-------------------+-----+------+\n",
      "|product_sid|product_id|            category|cogs|contains_caffeine|contains_fruit|contains_nuts|contains_veggies|          event_time|           item|       meta_hashdiff|   meta_ingestion_ts|meta_is_current|meta_sequence|     meta_valid_from|      meta_valid_to|price|  size|\n",
      "+-----------+----------+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+---------------+--------------------+--------------------+---------------+-------------+--------------------+-------------------+-----+------+\n",
      "|          0|      CS07|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-18 19:26:...|Blueberry Bliss|15cc375354ec3db62...|2024-02-20 20:14:...|           true|            3|2024-02-18 19:26:...|9999-12-31 00:00:00| 4.99|24 oz.|\n",
      "|          0|      CS07|   Classic Smoothies| 1.5|            false|          true|        false|           false|2024-02-18 19:26:...|Blueberry Bliss|15cc375354ec3db62...|2024-02-20 20:14:...|           true|            3|2024-02-18 19:26:...|9999-12-31 00:00:00| 4.99|24 oz.|\n",
      "|          1|      SF02|Superfoods Smoothies| 2.1|            false|          true|        false|            true|2024-02-18 19:26:...|  Totally Green|44cf7ea4a75ebbc56...|2024-02-20 20:14:...|           true|            3|2024-02-18 19:26:...|9999-12-31 00:00:00| 5.99|24 oz.|\n",
      "|          1|      SF02|Superfoods Smoothies| 2.1|            false|          true|        false|            true|2024-02-18 19:26:...|  Totally Green|44cf7ea4a75ebbc56...|2024-02-20 20:14:...|           true|            3|2024-02-18 19:26:...|9999-12-31 00:00:00| 5.99|24 oz.|\n",
      "|          2|      SC03|Supercharged Smoo...| 2.7|            false|         false|         true|           false|2024-02-18 19:26:...|     Health Nut|120309dc5be633e6a...|2024-02-20 20:14:...|           true|            3|2024-02-18 19:26:...|9999-12-31 00:00:00| 5.99|24 oz.|\n",
      "+-----------+----------+--------------------+----+-----------------+--------------+-------------+----------------+--------------------+---------------+--------------------+--------------------+---------------+-------------+--------------------+-------------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from silver_purchase_scd1\").show(5)\n",
    "spark.sql(\"select * from silver_inventory_scd1\").show(5)\n",
    "spark.sql(\"select * from silver_product_scd2 order by product_sid\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_gold_dimension_table():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_dim_table_references\n",
    "\n",
    "def create_gold_fact_table(\n",
    "    source : str, \n",
    "    target : str,\n",
    "    surrogate_key : str,\n",
    "    timestamp_key : str,\n",
    "    dim_table_refs : dict\n",
    "):\n",
    "\n",
    "    # Generate and run SQL query\n",
    "    df = spark.sql(generate_dim_table_references(source, timestamp_key, dim_table_refs))\n",
    "\n",
    "    # Reorder columns in dataframe\n",
    "    df = reorder_columns_in_dataframe(\n",
    "        df=df, \n",
    "        columns_to_front=[surrogate_key] + [r[\"surrogate_key\"] for r in dim_table_refs],\n",
    "        columns_to_back=[c for c in df.columns if \"meta_\" in c]\n",
    "    )\n",
    "\n",
    "    # Create an empty Delta table with the same schema\n",
    "    tmp_view_name = \"temporaryView\"\n",
    "    df.createOrReplaceTempView(tmp_view_name)\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {target} LIKE {tmp_view_name} USING DELTA\")\n",
    "\n",
    "    # Merge into target table \n",
    "    merge_query = f\"\"\"\n",
    "        MERGE INTO {target} AS target\n",
    "        USING {tmp_view_name} AS source ON target.{surrogate_key} = source.{surrogate_key}\n",
    "        WHEN MATCHED AND target.meta_hashdiff <> source.meta_hashdiff THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\"\n",
    "\n",
    "    spark.sql(merge_query).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT src.*, silver_product_scd2.product_sid \n",
      "FROM silver_purchase_scd1 src\n",
      "LEFT JOIN silver_product_scd2 ON silver_product_scd2.product_id = src.product_id\n",
      "        AND src.transaction_time BETWEEN silver_product_scd2.meta_valid_from AND silver_product_scd2.meta_valid_to\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                0|               0|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n",
      "SELECT src.*, silver_product_scd2.product_sid \n",
      "FROM silver_inventory_scd1 src\n",
      "LEFT JOIN silver_product_scd2 ON silver_product_scd2.product_id = src.product_id\n",
      "        AND src.event_time BETWEEN silver_product_scd2.meta_valid_from AND silver_product_scd2.meta_valid_to\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                0|               0|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_gold_fact_table (\n",
    "    source=\"silver_purchase_scd1\",\n",
    "    target=\"gold_fact_purchase\",\n",
    "    surrogate_key=\"transaction_sid\",\n",
    "    timestamp_key=\"transaction_time\",\n",
    "    dim_table_refs=[{\"table_name\": \"silver_product_scd2\", \"merge_key\": \"product_id\", \"surrogate_key\": \"product_sid\"}]\n",
    ")\n",
    "\n",
    "create_gold_fact_table (\n",
    "    source=\"silver_inventory_scd1\",\n",
    "    target=\"gold_fact_inventory\",\n",
    "    surrogate_key=\"inventory_sid\",\n",
    "    timestamp_key=\"event_time\",\n",
    "    dim_table_refs=[{\"table_name\": \"silver_product_scd2\", \"merge_key\": \"product_id\", \"surrogate_key\": \"product_sid\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+---------+---------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|transaction_sid|add_supplements|is_member|member_discount|price|product_id|quantity|supplement_price|total_purchase|     transaction_id|    transaction_time|       meta_hashdiff|   meta_ingestion_ts|   meta_last_updated|product_sid|\n",
      "+---------------+---------------+---------+---------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|              0|           true|    false|            0.0| 4.99|      CS07|       2|            1.99|         13.96|1830085331582317580|2024-02-17 19:27:...|61f75a7278ee6b97a...|2024-02-20 20:14:...|2024-02-20 20:17:...|34359738371|\n",
      "|              1|           true|    false|            0.0| 5.99|      SF07|       2|            1.99|         15.96|2582918047038672240|2024-02-17 19:28:...|2498c9c86aebcfecf...|2024-02-20 20:14:...|2024-02-20 20:17:...|25769803779|\n",
      "|              2|          false|    false|            0.0| 5.99|      SC03|       2|             0.0|         11.98|6679341482214175713|2024-02-17 19:29:...|85cde6aebb6d2deb7...|2024-02-20 20:14:...|2024-02-20 20:17:...|34359738373|\n",
      "|              3|           true|    false|            0.0| 4.99|      CS06|       2|            1.99|         13.96|4642186432042039094|2024-02-17 19:32:...|f733a0370ead91420...|2024-02-20 20:14:...|2024-02-20 20:17:...|51539607553|\n",
      "|              4|          false|    false|            0.0| 5.49|      IS02|       2|             0.0|         10.98|7153639856726240807|2024-02-17 19:33:...|d98e4aac5b2c40a22...|2024-02-20 20:14:...|2024-02-20 20:17:...| 8589934594|\n",
      "+---------------+---------------+---------+---------------+-----+----------+--------+----------------+--------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+--------------------+--------------+---------+----------+--------------+--------------------+--------------------+--------------------+-----------+\n",
      "|inventory_sid|          event_time|existing_level|new_level|product_id|stock_quantity|       meta_hashdiff|   meta_ingestion_ts|   meta_last_updated|product_sid|\n",
      "+-------------+--------------------+--------------+---------+----------+--------------+--------------------+--------------------+--------------------+-----------+\n",
      "|            0|2024-02-17 19:28:...|            34|       44|      SC04|            10|0d93648fbc91fd6f5...|2024-02-20 20:14:...|2024-02-20 20:17:...|34359738374|\n",
      "|            1|2024-02-17 19:28:...|            49|       59|      SF07|            10|6990e55cf2125fc32...|2024-02-20 20:14:...|2024-02-20 20:17:...|25769803779|\n",
      "|            2|2024-02-17 19:28:...|            43|       53|      SC04|            10|add0004a8cd62da10...|2024-02-20 20:14:...|2024-02-20 20:17:...|34359738374|\n",
      "|            3|2024-02-17 19:28:...|            42|       52|      SC01|            10|86a18c18d7b12e8eb...|2024-02-20 20:14:...|2024-02-20 20:17:...|42949672964|\n",
      "|            4|2024-02-17 19:28:...|            49|       59|      SF02|            10|20274ea879588afb5...|2024-02-20 20:14:...|2024-02-20 20:17:...|34359738372|\n",
      "+-------------+--------------------+--------------+---------+----------+--------------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from gold_fact_purchase\").show(5)\n",
    "spark.sql(\"select * from gold_fact_inventory\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
